# iOS 2021 面试前的准备（总结各知识点方便面试前快速复习使用）（三）

> &emsp;博主前期通读了 Apple 的五份源码 [objc4-781](https://opensource.apple.com/tarballs/objc4/)、[libdispatch-1173.40.5](https://opensource.apple.com/tarballs/libdispatch/)、[CF-1151.16](https://opensource.apple.com/tarballs/CF/)、[libmalloc-283.100.6](https://opensource.apple.com/tarballs/libmalloc/)、[libclosure-74](https://opensource.apple.com/source/libclosure/) 基本对 iOS 的大部分底层原理都有了一个基础的认知，然后算法部分的话是专注刷了两遍 《剑指 Offer》（在 IDE 里可以完成默写，完全手写的话可能还需要一些练习）。那么既然是面试肯定免不了要刷题，题目的话就从网络搜集各位大佬面试时的题目以及本人面试时被问到的题目，然后试着从自己的理解上给题目作出解答，如有错误的地方还望大家进行指正。   

## 21. dispatch_semaphore 的实现原理。
&emsp;dispatch_semaphore 是 GCD 中提供的一个很常用的操作，通常用于保证资源的多线程安全性和控制任务的并发数量。其本质实际上是基于 mach 内核的信号量接口来实现的。

&emsp;`dispatch_semaphore_t` 是指向 `dispatch_semaphore_s` 结构体的指针。首先看一下基础的数据结构。
```c++
struct dispatch_queue_s;

DISPATCH_CLASS_DECL(semaphore, OBJECT);
struct dispatch_semaphore_s {
    DISPATCH_OBJECT_HEADER(semaphore);
    
    // 可看到上半部分的宏定义和其它的 GCD 类是相同的，毕竟大家都是继承自 dispatch_object_s，重点是下面两个新的成员变量，
    // dsema_value 和 dsema_orig 是信号量执行任务的关键，执行一次 dispatch_semaphore_wait 操作，dsema_value 的值就做一次减操作。
    
    long volatile dsema_value;
    long dsema_orig;
    _dispatch_sema4_t dsema_sema;
};
```
&emsp;`dispatch_semaphore_s` 结构体中：`dsema_orig` 是信号量的初始值，`dsema_value` 是信号量的当前值，信号量的相关 API 正是通过操作 `dsema_value` 来实现其功能的。

&emsp;`dispatch_semaphore_create` 用初始值（`long value`）创建新的计数信号量。当两个线程需要协调特定事件的完成时，将值传递为零非常有用。传递大于零的值对于管理有限的资源池非常有用，该资源池的大小等于该值（例如我们有多个文件要从服务器下载下来，然后用 dispatch_semaphore 限制只能并发五条线程（`dispatch_semaphore_create(5)`）进行下载）。

&emsp;参数 `value`：信号量的起始值，传递小于零的值将导致返回 `NULL`。返回值 `result`：新创建的信号量，失败时为 `NULL`。

&emsp;`dispatch_semaphore_wait` 等待（减少）信号量。
```c++
long
dispatch_semaphore_wait(dispatch_semaphore_t dsema, dispatch_time_t timeout)
{
    // 原子操作 dsema 的成员变量 dsema_value 的值减 1
    long value = os_atomic_dec2o(dsema, dsema_value, acquire);
    
    // 如果减 1 后仍然大于等于 0，则直接 return 
    if (likely(value >= 0)) {
        return 0;
    }
    
    // 如果小于 0，则调用 _dispatch_semaphore_wait_slow 函数进行阻塞等待
    return _dispatch_semaphore_wait_slow(dsema, timeout);
}
```
&emsp;减少计数信号量，如果结果值小于零，此函数将等待信号出现，然后返回。（可以使总信号量减 1，信号总量小于 0 时就会一直等待（阻塞所在线程），否则就可以正常执行。）`dsema`：信号量，在此参数中传递 `NULL` 的结果是未定义的。`timeout`：何时超时（dispatch_time），为方便起见，有 `DISPATCH_TIME_NOW` 和 `DISPATCH_TIME_FOREVER` 常量。函数返回值 `result`，成功返回零，如果发生超时则返回非零（`_DSEMA4_TIMEOUT`）。

&emsp;当 `timeout` 是 `DISPATCH_TIME_FOREVER` 时，do while 循环一直等下去，直到 `sema` 的值被修改为不等于 `KERN_ABORTED`。
```c++
void
_dispatch_sema4_wait(_dispatch_sema4_t *sema)
{
    kern_return_t kr;
    do {
        kr = semaphore_wait(*sema);
    } while (kr == KERN_ABORTED);
    
    DISPATCH_SEMAPHORE_VERIFY_KR(kr);
}
```
&emsp;其中调用了 mach 内核的信号量接口 `semaphore_wait` 和 `semaphore_timedwait` 进行 wait 操作。所以，GCD 的信号量实际上是基于 mach 内核的信号量接口来实现。`semaphore_timedwait` 函数即可以指定超时时间。

&emsp;`dispatch_semaphore_signal` 发信号（增加）信号量。如果先前的值小于零，则此函数在返回之前唤醒等待的线程。如果线程被唤醒，此函数将返回非零值。否则，返回零。
```c++
long
dispatch_semaphore_signal(dispatch_semaphore_t dsema)
{
    // 原子操作 dsema 的成员变量 dsema_value 的值加 1
    long value = os_atomic_inc2o(dsema, dsema_value, release);
    
    if (likely(value > 0)) {
        // 如果 value 大于 0 表示目前没有线程需要唤醒，直接 return 0
        return 0;
    }
    
    // 如果过度释放，导致 value 的值一直增加到 LONG_MIN（溢出），则 crash 
    if (unlikely(value == LONG_MIN)) {
        DISPATCH_CLIENT_CRASH(value, "Unbalanced call to dispatch_semaphore_signal()");
    }
    
    // value 小于等于 0 时，表示目前有线程需要唤醒
    return _dispatch_semaphore_signal_slow(dsema);
}
```

&emsp;`_dispatch_semaphore_signal_slow` 内部调用 `_dispatch_sema4_signal(&dsema->dsema_sema, 1)` 唤醒一条线程。
```c++
DISPATCH_NOINLINE
long _dispatch_semaphore_signal_slow(dispatch_semaphore_t dsema) {
    _dispatch_sema4_create(&dsema->dsema_sema, _DSEMA4_POLICY_FIFO);
    
    // count 传 1，唤醒一条线程
    _dispatch_sema4_signal(&dsema->dsema_sema, 1);
    
    return 1;
}
```
&emsp;`semaphore_signal` 能够唤醒一个在 `semaphore_wait` 中等待的线程。如果有多个等待线程，则根据线程优先级来唤醒。
```c++
void
_dispatch_sema4_signal(_dispatch_sema4_t *sema, long count)
{
    do {
        // semaphore_signal 唤醒线程
        kern_return_t kr = semaphore_signal(*sema);
        DISPATCH_SEMAPHORE_VERIFY_KR(kr);
    } while (--count);
}
```

***

## 22. dispatch_group 的实现原理。
&emsp;dispatch_group 可以将一组 GCD 任务关联到一起，可以监听这一组所有任务的执行情况，当所有任务异步执行完毕后我们可以得到一个或多个回调通知（使用 `dispatch_group_notify` 添加几个就能执行几个回调通知）。（dispatch_group 不持有与它相关的任务 block，但是会通过链表的形式持有 `dispatch_group_notify` 函数添加的回调通知 block）

&emsp;`dispatch_group_s` 定义和 `dispatch_semaphore_s` 定义都是放在 semaphore_internal.h 文件中，而且该文件中仅包含它俩的内容，其实文件这样布局也是有用意的，因为它俩的内部实现有一些相似性，dispatch_group 在内部也会维护一个值，当调用 `dispatch_group_enter` 函数进行进组操作时（`dg_bits` - `0x0000000000000004ULL`），当调用 `dispatch_group_leave` 函数进行出组操作时（`dg_state` + `0x0000000000000004ULL`）时对该值进行操作（这里可以把 `dg_bits` 和 `dg_state` 理解为一个值），当该值达到临界值 0 时会做一些后续操作（`_dispatch_group_wake` 唤醒异步执行 `dispatch_group_notify` 函数添加的所有回调通知），且在使用过程中一定要谨记进组（enter）和出组（leave）必须保持平衡。

&emsp;假设与 dispatch_group 关联的 GCD 任务是一个 block，dispatch_group 并不持有此 block，甚至 dispatch_group 与此 block 没有任何关系，dispatch_group 内部的那个值只是与 enter/leave 操作有关，GCD 任务只是借用了此值，例如在创建多个 GCD 异步任务之前调用多次 enter 操作，然后在每个 GCD 任务结束时调用 leave 操作，当这多个 GCD 异步任务都执行完毕，那么如果 dispatch_group 添加了回调通知，此时自会收到回调通知。即使我们使用 dispatch_group_async 创建多个 GCD 异步任务 block， 这些 GCD 任务 block 其实与 dispatch_group 也没有任何直接的关系。

&emsp;那么与这些 GCD 异步任务相比的话，我们使用 `dispatch_group_notify` 函数添加的多个回调通知的 block 则是被 dispatch_group 所完全拥有的，这些回调通知 block 会链接成一个链表，而 dispatch_group 实例则直接拥有此链表的头节点和尾节点。

&emsp;`dispatch_group_t` 是指向 `dispatch_group_s` 结构体的指针，`dispatch_group_s` 结构体的定义如下。
```c++
DISPATCH_CLASS_DECL(group, OBJECT);
struct dispatch_group_s {
    DISPATCH_OBJECT_HEADER(group);
    // 可看到上半部分和其它 GCD 对象都是相同的，毕竟大家都是继承自 dispatch_object_s，重点是下面的新内容 
    
    union { 
        uint64_t volatile dg_state;  // leave 时加 DISPATCH_GROUP_VALUE_INTERVAL
        struct { 
            uint32_t dg_bits; // enter 时减 DISPATCH_GROUP_VALUE_INTERVAL
            
            // 主要用于 dispatch_group_wait 函数被调用后，
            // 当 dispath_group 处于 wait 状态时，结束等待的条件有两条：
            // 1): 当 dispatch_group 关联的 block 都执行完毕后，wait 状态结束
            // 2): 当到达了指定的等待时间后，即使关联的 block 没有执行完成，也结束 wait 状态 
            
            // 而当 dg_gen 不为 0 时，说明 dg_state 发生了进位，可表示 dispatch_group 关联的 block 都执行完毕了，
            // 如果 dispatch_group 此时处于 wait 状态的话就可以结束了，此时正对应上面结束 wait 状态的条件 1 中。
            uint32_t dg_gen;
        };
    } __attribute__((aligned(8)));
    
    // 下面两个成员变量比较特殊，它们分别是一个链表的头节点指针和尾节点指针
    // 调用 dispatch_group_notify 函数可添加当 dispatch_group 关联的 block 异步执行完成后的回调通知，
    // 多次调用 dispatch_group_notify 函数可添加多个回调事件（我们日常开发一般就用了一个回调事件，可能会忽略这个细节），
    // 而这些多个回调事件则会构成一个 dispatch_continuation_s 作为节点的链表，当 dispatch_group 中关联的 block 全部执行完成后，
    // 此链表中的 dispatch_continuation_s 都会得到异步执行。
    //（注意是异步，具体在哪个队列则根据 dispatch_group_notify 函数的入参决定，以及执行的优先级则根据队列的优先级决定）。
    
    struct dispatch_continuation_s *volatile dg_notify_head; // dispatch_continuation_s 链表的头部节点
    struct dispatch_continuation_s *volatile dg_notify_tail; // dispatch_continuation_s 链表的尾部节点
};
```
&emsp;`dg_bits` 和 `dg_state` 是联合体共享同一块内存空间的不同名的成员变量，进组和出组时减少和增加 `DISPATCH_GROUP_VALUE_INTERVAL` 操作的其实是同一个值，再详细一点的话是联合体共占用 64 bit 空间，其中 uint64_t 类型的 dg_state 可占完整 64 bit，然后 uint32_t 类型的 `dg_bits` 和  uint32_t 类型的 `dg_gen` 组成结构体共占用这 64 bit，其中 `dg_bits` 在 低 32 bit，`dg_gen` 在高 32 bit。

&emsp; GCD  任务 block 与 dispatch_group 关联的方式：

+ 调用 `dispatch_group_enter` 表示一个 block 与 dispatch_group 关联，同时 block 执行完后要调用 `dispatch_group_leave` 表示解除关联，否则 `dispatch_group_s` 会永远等下去。
+ 调用 `dispatch_group_async` 函数与 block  关联，其实它是在内部封装了一对 enter 和 leave 操作。

&emsp;在 dispatch_group 进行进组出组操作每次是用加减 4 （`DISPATCH_GROUP_VALUE_INTERVAL`）来记录的，并不是常见的加 1 减 1，然后起始值是从 uint32_t 的最小值 0 开始的，这里用了一个无符号数和有符号数的转换的小技巧，例如 dispatch_group 起始状态时 uint32_t 类型的 `dg_bits` 值为 0，然后第一个 enter 操作进来以后，把 uint32_t 类型的 `dg_bits` 从 0 减去 4，然后 -4 转换为 uint32_t 类型后值为 4294967292，然后 leave 操作时 `dg_bits` 加 4，即 4294967292 加 4，这样会使 uint32_t 类型值溢出然后 `dg_bits` 值就变回 0 了（uint32_t 类型的最小值），对应到 dispatch_group 中的逻辑原理即表示 `dg_bits` 达到临界值了，表示与组关联的 block 都执行完成了，可以执行后续的唤醒操作了。

&emsp;还有一点，`dg_bits` 使用 32 bit 空间对应使用 uint32_t 类型，然后 `DISPATCH_GROUP_VALUE_INTERVAL`（间隔）用 4 是因为 uint32_t 类型表示的数字个数刚好是 4 的整数倍吗，不过只要是 2 的幂都是整数倍，且 uint32_t 类型的数字即使以 4 为间隔表示的数字个数也完全足够使用了， 这里的还包括了掩码的使用，4 的二进制表示时后两位是 0，正好可以用来表示两个掩码位，仅后两位是 1 时分别对应 `DISPATCH_GROUP_HAS_NOTIFS`（表示 dispatch_group 是否有 notify 回调通知的掩码）和 `DISPATCH_GROUP_HAS_WAITERS`（对应 dispatch_group_wait 函数的使用，表示 dispatch_group 是否处于等待状态的掩码）。

&emsp;`dispatch_group_async` 将一个 block 提交到指定的调度队列并进行异步调用，并将该 block 与给定的 dispatch_group 关联（其内部自动插入了 `dispatch_group_enter` 和 `dispatch_group_leave` 操作，相当于 `dispatch_async` 和 `dispatch_group_enter`、`dispatch_group_leave` 三个函数的一个封装）。和我们自己手动调用 enter、leave、dispatch_async 相比 dispatch_group_async 轻松了不少，可以让我们更专注于 GCD 任务的编写。

&emsp;还有一个点这里要注意一下，把入参 block `db` 封装成 `dispatch_continuation_t`  `dc` 的过程中，会把 `dc_flags` 设置为 `DC_FLAG_CONSUME | DC_FLAG_GROUP_ASYNC`，这里的 `DC_FLAG_GROUP_ASYNC` 标志关系到 `dc` 执行的时候调用的具体函数（这里的提交的任务的 block 和 dispatch_group 关联的点就在这里，`dc` 执行时会调用 `_dispatch_continuation_with_group_invoke(dc)`，而我们日常使用的 `dispatch_async` 函数提交的异步任务的 block 执行的时候调用的是 `_dispatch_client_callout(dc->dc_ctxt, dc->dc_func)` 函数，它们正是根据 `dc_flags` 中的 `DC_FLAG_GROUP_ASYNC` 标识来区分的。

&emsp;`dispatch_group_notify` 函数，当与 dispatch_group 相关联的所有 block 都已完成时，计划将 `db` 提交到队列 `dq`（即当与 dispatch_group 相关联的所有 block 都已完成时，notify 添加的回调通知将得到执行）。如果没有 block 与 dispatch_group 相关联，则通知块 `db` 将立即提交。如下代码中通知块 `db` 将立即被调用。

```c++
dispatch_group_t group = dispatch_group_create();
// dispatch_group_notify 提交的回调 block 立即得到执行
dispatch_group_notify(group, globalQueue, ^{
    NSLog(@"🏃‍♀️ %@", [NSThread currentThread]);
});
// 控制台打印:
 🏃‍♀️ <NSThread: 0x600000fcbe00>{number = 5, name = (null)}
```

&emsp;通知块 `db` 提交到目标队列 `dq` 时，该 dispatch_group 关联的 block 将为空，或者说只有该 dispatch_group 关联的 block 为空时，通知块 `db` 才会提交到目标队列 `dq`。此时可以通过 `dispatch_release` 释放 dispatch_group，也可以重新用于其他操作。

&emsp;`dispatch_group_notify` 函数不会阻塞当前线程，此函数会立即返回，如果我们想阻塞当前线程，想要等 dispatch_group 中关联的 block 全部执行完成后才执行接下来的操作时，可以使用 `dispatch_group_wait` 函数并指定具体的等待时间（`DISPATCH_TIME_FOREVER`）。

&emsp;`os_atomic_rmw_loop2o` 是一个宏定义，内部包裹了一个 do while 循环，直到 old_state == 0 时跳出循环执行 `_dispatch_group_wake` 函数唤醒执行 notify 链表中的回调通知，即对应我们上文中的 `dispatch_group_leave` 函数中 `dg_bits` 的值回到 0 表示 `dispatch_group` 中关联的 block 都执行完了。

&emsp;`dispatch_group_wait` 函数同步等待直到与 dispatch_group 关联的所有 block 都异步执行完成或者直到指定的超时时间过去为止，才会返回。如果没有与 dispatch_group 关联的 block，则此函数将立即返回。从多个线程同时使用同一 dispatch_group 调用此函数的结果是不确定的。成功返回此函数后，dispatch_group 关联的 block 为空，可以使用 `dispatch_release` 释放 dispatch_group，也可以将其重新用于其它 block。

&emsp;`dispatch_group_wait` 函数内部使用同上面的 os_atomic_rmw_loop2o 宏定义，内部是一个 do while 循环，每次循环都从本地原子取值，判断 dispatch_group 所处的状态，是否关联的 block 都异步执行完毕了。

&emsp;`_dispatch_group_wake` 把  notify 回调函数链表中的所有的函数提交到指定的队列中异步执行，`needs_release` 表示是否需要释放所有关联 block 异步执行完成、所有的 notify 回调函数执行完成的 dispatch_group 对象。`dg_state` 则是 dispatch_group 的状态，包含目前的关联的 block 数量等信息。

## 23. dispatch_barrier_async 的实现原理。
&emsp;`dispatch_barrier_async` 提交 barrier block 以在指定的调度队列上异步执行，同 `dispatch_async` 函数一样不会阻塞当前线程，此函数会直接返回并执行接下来的函数语句。`dispatch_barrier_async` 的作用是对添加到同一并发队列中的异步任务作出 “排序”。

```c++
- (void)viewDidLoad {
    [super viewDidLoad];
    
    dispatch_queue_t concurrentQueue = dispatch_queue_create("com.concurrent", DISPATCH_QUEUE_CONCURRENT);
    
    NSLog(@"🔞 START: %@", [NSThread currentThread]);
    
    dispatch_async(concurrentQueue, ^{ sleep(3); NSLog(@"🏃‍♀️ %@", [NSThread currentThread]);}); // ⬅️ 任务一
    dispatch_async(concurrentQueue, ^{ sleep(4); NSLog(@"🏃‍♀️🏃‍♀️ %@", [NSThread currentThread]);});// ⬅️ 任务二
    
    dispatch_barrier_async(concurrentQueue, ^{ sleep(3); NSLog(@"🚥🚥 %@", [NSThread currentThread]);}); // ⬅️ Barrie 任务
    
    dispatch_async(concurrentQueue, ^{ sleep(3); NSLog(@"🏃‍♀️🏃‍♀️🏃‍♀️ %@", [NSThread currentThread]);}); // ⬅️ 任务三
    dispatch_async(concurrentQueue, ^{ sleep(2); NSLog(@"🏃‍♀️🏃‍♀️🏃‍♀️🏃‍♀️ %@", [NSThread currentThread]);}); // ⬅️ 任务四
    
    NSLog(@"🔞 END: %@", [NSThread currentThread]);
}
```
&emsp;首先四个任务都不会阻塞主线程，两条 🔞 的打印会首先执行完毕，然后是任务一和任务二异步并发执行，当它们全部都执行完毕以后，开始异步执行 Barrie 任务，当 Barrie 任务 执行完毕以后，才开始异步并发执行任务三和任务四，这样就像在前两个任务和后两个任务之间插了一道无形的墙，使在 Barrie 任务之前添加的任务和之后添加的任务有了执行顺序，这就是 `dispatch_barrier_async` 函数的作用，可以在多个异步并发任务之间添加执行顺序。

&emsp;`dq` 参数是 Barrier block 提交到的目标调度队列，这里要注意把需要控制异步并发执行顺序的任务都添加到同一个自定义的并发队列 `dq` 中，同时注意不能使用 `dispatch_get_global_queue` API 获取的全局并发队列中（会导致 Barrier 失效，因为全局并发队列是系统创建的，苹果有时候会在全局并发队列中处理它自有任务，使用 barrier 函数阻塞全局并发队列无效），系统将在目标队列上保留引用，直到该 block 执行完成为止。

&emsp;`work` 参数是提交到目标调度队列的 block（该函数内部会代表调用者执行 `Block_copy` 和 `Block_release`）。
```c++
#ifdef __BLOCKS__
void
dispatch_barrier_async(dispatch_queue_t dq, dispatch_block_t work)
{
    // 取得一个 dispatch_continuation_s 结构体实例，用于封装 work
    dispatch_continuation_t dc = _dispatch_continuation_alloc();
    
    // continuation resources are freed on run this is set on async or for non event_handler source handlers
    // #define DC_FLAG_CONSUME  0x004ul
    // continuation acts as a barrier
    // #define DC_FLAG_BARRIER  0x002ul
    // DC_FLAG_CONSUME | DC_FLAG_BARRIER = 0x006ul
    
    // dc_flags 中添加 DC_FLAG_BARRIER 标记，标记此 work 是一个屏障 block，然后剩下的内容都和 dispatch_async 完全相同
    uintptr_t dc_flags = DC_FLAG_CONSUME | DC_FLAG_BARRIER;
    
    dispatch_qos_t qos;
    
    // 封装 work block 的内容以及任务执行时所处的队列等内容到 dc 中
    qos = _dispatch_continuation_init(dc, dq, work, 0, dc_flags);
    
    // 把封装好的 dispatch_continuation_s 进行异步调用
    _dispatch_continuation_async(dq, dc, qos, dc_flags);
}
#endif
```
&emsp;看到 `dispatch_barrier_async` 函数内部和 `dispatch_async` 相比在 `dc_flags` 赋值时添加了 `DC_FLAG_BARRIER` 标记，而此标记正是告知 `dispatch_continuation_s` 结构体中封装的 block 是一个 barrier block，其它的内容则和 `dispatch_async` 如出一辙。

&emsp;一个 `dispatch barrier` 允许你在一个并行队列中创建一个同步点。当在队列中遇到这个 `barrier block` 时，这个 `barrier block` 便会延迟执行（同时所有在其后的 block 都会延迟），直至所有在 barrier 之前的 block 执行完成。这时，这个 `barrier block` 便会执行，之后队列便恢复正常执行。

&emsp;调用这个函数总是会在这个 block 被提交后立刻返回，并且不会等到 block 被触发。当这个 `barrier block` 到达私有并行 队列最前端时，它不是立即执行。恰恰相反，这个队列会一直等待当前正在执行的队列执行完成。此时 `barrier block` 才会执行。所有 `barrier block` 之后提交的 block 会等到 `barrier block` 执行结束后才会执行。

&emsp;这里你指定的并行队列应该是自己通过 `dispatch_queue_cretate` 创建的。如果你传的是一个串行或是一个全局的并行队列，那这个函数便等同于 `dispatch_async` 函数效果了。

***

## 24. 介绍 run loop 的概念（run loop 与线程的关系）。
&emsp;Run loop 是与 thread 关联的基本基础结构的一部分。Run loop 是一个 event processing loop （事件处理循环），可用于计划工作并协调收到的事件的接收。Run loop 的目的是让 thread 在有工作要做时保持忙碌，而在没有工作时让 thread 进入睡眠状态。

&emsp;一般来讲，一个线程一次只能执行一个任务，执行完成后线程就会退出。如果我们需要一个机制，让线程能随时处理事件但并不退出，这种模型通常被称作 Event Loop。实现这种模型的关键点在于基于消息机制：管理事件/消息，让线程在没有消息时休眠以避免资源占用、在有消息到来时立刻被唤醒执行任务。

&emsp;那什么是 run loop？顾名思义，run loop 就是在 “跑圈”，run loop 运行的核心代码是一个有状态的 do while 循环，每循环一次就相当于跑了一圈，线程就会对当前这一圈里面产生的事件进行处理，并且只要不是超时或者故意退出状态下 run loop 就不会退出，所以可以保证线程不退出，并且可以让我们根据自己需要向线程中添加任务。

&emsp;那么为什么线程要有 run loop 呢？其实我们的 APP 可以理解为是靠 event 驱动的（包括 iOS 和 Android 应用）。我们触摸屏幕、网络回调等都是一个个的 event，也就是事件。这些事件产生之后会分发给我们的 APP，APP 接收到事件之后分发给对应的线程。通常情况下，如果线程没有 run loop，那么一个线程一次只能执行一个任务，执行完成后线程就会退出。要想 APP 的线程一直能够处理事件或者等待事件（比如异步事件），就要保活线程，也就是不能让线程早早的退出，此时 run loop 就派上用场了，其实也不是必须要给线程指定一个 run loop，如果需要我们的线程能够持续的处理事件，那么就需要给线程绑定一个 run loop，也就是说，run loop 能够保证线程一直可以处理事件。

&emsp;run loop 与线程的关系：一个线程对应一个 run loop，程序运行是主线程的 main run loop 默认启动了，所以我们的程序才不会退出，子线程的 run loop 按需启动（调用 run 方法）。run loop 是线程的事件管理者，或者说是线程的事件管家，它会按照顺序管理线程要处理的事件，决定哪些事件在什么时候提交给线程处理。（run loop 内部是基于内核基于 mach port 进行工作的）

&emsp;在开发者文档中查看 `UIApplicationMain` 函数，摘要告诉我们 `UIApplicationMain` 函数完成：**创建应用程序对象和应用程序代理并设置 event cycle**，看到 Return Value 一项 Apple 已经明确告诉我们 `UIApplicationMain` 函数是不会返回的，并且在 Discussion 中也告诉我们 `UIApplicationMain` 函数启动了 main run loop 并开始着手为我们处理事件。

```c++
int main(int argc, char * argv[]) {
    @autoreleasepool {
        int retVal = 0;
        do {
            // 在睡眠中等待消息
            int message = sleep_and_wait();
            // 处理消息
            retVal = process_message(message);
        } while (retVal == 0);
        return 0;
    }
}
```













## 什么是 ARC 以及 ARC 的工作原理，ARC 下会存在内存泄漏吗？

***

## UIView 与 CALayer  CoreAnimation 

***
